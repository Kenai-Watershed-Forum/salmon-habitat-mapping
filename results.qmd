# Results

```{r , include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

# clear environment
rm(list=ls())

# load packages
library(tinytex)
library(tidyverse)
library(googlesheets4)
library(lubridate)
library(readr)
library(readxl)
library(writexl)
library(hms)
library(DT)
library(xlsx)
library(leaflet)
library(DT)
library(ggpubr)
library(plotrix)
library(packrat)
library(foreign)
library(kableExtra)
library(janitor)
library(anytime)
library(stringr)

# set plotting themes

## geom_col plots theme
col_theme <- theme(axis.title = element_text(size = 14, face = "bold"),
                   strip.text = element_text(size = 14, face = "bold"),
                   legend.title = element_text(size = 14, face = "bold"),
                   legend.text = element_text(size = 14),
                   axis.text = element_text(size = 14))

## geom_points plots theme
points_theme <- theme(axis.title = element_text(size = 14, face = "bold"),
                   strip.text = element_text(size = 14, face = "bold"),
                   legend.title = element_text(size = 14, face = "bold"),
                   legend.text = element_text(size = 14),
                   axis.text = element_text(size = 11, face = "bold"),
                   title = element_text(size = 18))

# function to exclude multiple items per column
'%ni%' <- Negate('%in%')

# clarify select function
select <- dplyr::select

# source function to recognize and convert columns to posix
source("functions/datetime_convert.R")
```

```{r echo = F}
# Notes

# In 2025 KWF transitioned from using paper field forms entered in a google sheet to using ESRI Field Maps to collect field data on mobile devices. The code chunks below treat the read-in processes from these two distinct data sources separately. For 2025, the ERSI data is being formatted to match the pre-existing data structure that was in place during the google sheets read-in process. 

# Fish capture data vs. sampling effort are organized separately in two tabs in a google sheets. We will attempt to organize the ESRI data to match the object "fish_dat" wherein they are combined.

# Long term suggested strategy: enter the 2021-2024 data from google sheets in to the ESRI database so it's all in one location

```

```{r echo = F}

# Read in and prepare Google Sheets data

## read in data from paper field forms
url <- "https://docs.google.com/spreadsheets/d/1S0hwY4EQo9Xtz5d4UnSBCbZoJ0ft_HGQrarfmA5dwNY/edit#gid=0"

## prep data sources

### sample events
sample_events <- read_sheet(url, sheet =  "A_Sample_Event") %>%
  # retain only TU events
  # filter(project_org == "TU") %>%
  transform(site_arrive_time = as_hms(site_arrive_time),
            site_depart_time = as_hms(site_depart_time)) %>%
  select(-QC1,-QC2,-data_entry,-notes,-crew)



### fish count
fish_dat <- read_sheet(url, sheet = "F_Fish_ID") %>%
  select(-QC1,-QC2,-data_entry)  %>%
  
  # inner join. Assumes that no other simultaneous fieldwork was done elsewhere that day
  inner_join(sample_events, by = c("site_depart_date","site")) %>%
  
  # transform column types
  transform(fl_mm = as.numeric(fl_mm),
            photo_id = as.character(photo_id),
            notes = as.character(notes))

```

```{r echo = F}

# Read in and prepare ESRI Field Maps data
# 1) Site/event information

# field maps data 2025 from ArcGIS Online
dat_field_maps <- read.csv("input/field_maps/kwf_stream_surveys_20251125.csv")

# prep to integrate into same format as paper field forms from 2021 - July 2025
dat_field_maps <- dat_field_maps %>%
  clean_names() %>%
  type_convert() 

# specify useful columns to retain
col_names <- (
  c(
  # sampling event
  "y","x", # latitude and longitude
  "survey_time_and_date",
  "observer1","observer2","observer3","observer4",
  "trap_deployment_time","trap_check_time",
  "electrofishing_start_time", "electrofishing_end_time",
  # fish capture
  "fish_count_1", "fish_life_stage_1", "fish_species_1", "fish_capture_1_notes",
  "fish_count_2", "fish_life_stage_2", "fish_species_2", "fish_capture_2_notes",
  "fish_count_3", "fish_life_stage_3", "fish_species_3", "fish_capture_3_notes",
  "fish_count_4", "fish_life_stage_4", "fish_species_4", "fish_capture_4_notes",
  "fish_count_5", "fish_life_stage_5", "fish_species_5", "fish_capture_5_notes",
  "fish_count_6", "fish_life_stage_6", "fish_species_6", "fish_capture_6_notes",
  "additional_fish_capture_data"
  )
)

# retain specified columns
dat_field_maps <- dat_field_maps %>%
  select(all_of(col_names)) %>%
  rename(latitude = y,
         longitude = x)

# apply "convert_to_datetime" function (posix conversion) to convert columns w/ date or time in column name
dat_field_maps <- dat_field_maps %>%
  mutate(
    across(
      .cols = where(is.character),
      .fns  = convert_to_datetime
    )
  )


# the data pipeline of Field Maps --> ArcGIS Online --> download csv and open in Excel removes the 8 hour UTC time zone offset. Thus we need to revert all date/times back to local Alaska time

# specify columns that need UTC -> Alaska conversion
time_cols <- c(
  "survey_time_and_date",
  "trap_deployment_time",
  "trap_check_time",
  "electrofishing_start_time",
  "electrofishing_end_time"
)

# convert time/date columns to AKST time zone
dat_field_maps <- dat_field_maps %>%
  mutate(
    across(
      all_of(time_cols),
      ~ .x %>%
        force_tz("UTC") %>%              # treat existing clock time as UTC
        with_tz("America/Anchorage")     # convert to Alaska local time
    )
  )


## Find all datetime (POSIXt) columns
datetime_cols <- dat_field_maps |>
  select(where(lubridate::is.POSIXt)) |>
  names()

## Create site arrival and departure time columns based on earliest and latest activity
dat_field_maps <- dat_field_maps |>
  rowwise() |>
  mutate(site_arrive_datetime = min(c_across(all_of(datetime_cols)), na.rm = TRUE),
         site_depart_datetime = max(c_across(all_of(datetime_cols)), na.rm = TRUE)) |>
  ungroup() %>%
  mutate(site_arrive_date = date(site_arrive_datetime),
         site_arrive_time = as_hms(site_arrive_datetime),
         site_depart_date = date(site_depart_datetime),
         site_depart_time = as_hms(site_depart_datetime))


# this result still contains extraneous columns. We will eliminate them as part of performing a bind_rows() later



# 2) Fish capture data

dat_field_maps <- dat_field_maps %>%
  # 1) Standardize the capture-notes names:
  #    fish_capture_1_notes -> fish_capture_notes_1, etc.
  rename_with(
    ~ str_replace(.x,
                  "^fish_capture_(\\d+)_notes$",
                  "fish_capture_notes_\\1"),
    starts_with("fish_capture_")
  ) %>%
  
  # 2) Pivot the 6 sets of fish_* columns into long format
  pivot_longer(
    cols = matches("^fish_(count|life_stage|species|capture_notes)_\\d+$"),
    names_to      = c(".value", "fish_set"),
    names_pattern = "fish_(count|life_stage|species|capture_notes)_(\\d+)",
    values_drop_na = FALSE
  ) %>%
  
  # 2a) (Optional) rename back to fish_* if you prefer
  rename(
    fish_count        = count,
    fish_species      = species,
    fish_life_stage   = life_stage,
    fish_capture_notes = capture_notes
  ) %>%
  
  # 3) Drop rows where all fish fields are NA
  filter(
    !(is.na(fish_count) &
      is.na(fish_species) &
      is.na(fish_life_stage) &
      is.na(fish_capture_notes))
  ) %>%
  
  # 4) Make fish_set an integer
  mutate(fish_set = as.integer(fish_set))


## prepare column content and names to match google sheets read in 
dat_field_maps <- dat_field_maps %>%
  # create new columns and rename existing ones
  mutate(site = "",
         observer_name = "",
         project_org = "KWF",
         species = fish_species,
         lifestage = fish_life_stage,
         count = fish_count,
         disposition = "ID'd and released",
         notes = paste(additional_fish_capture_data,";",fish_capture_notes),
         observer_name = "Benjamin Meyer") %>%
  select(-contains("datetime"))

```

```{r }
# change scientific species names to common names

## ---------------------------------------------- -------------
## 1) Read species mapping from Excel (common + scientific)
##    File: other/arp_freshwater_data_form_2025.xlsx
##    Sheet: "Cell Drop Down List"
##    Range: rows 46–137, columns B (common) and C (scientific)
## -----------------------------------------------------------

species_map <- read_excel(
  "other/arp_freshwater_data_form_2025.xlsx",
  sheet    = "Cell Drop Down List",
  range    = "B46:C137",
  col_names = c("common_name", "scientific_name")
) %>%
  mutate(
    common_name     = str_squish(as.character(common_name)),
    scientific_name = str_squish(as.character(scientific_name))
  ) %>%
  filter(!is.na(common_name)) %>%
  rename(fish_species = scientific_name)


## 2 join common name to species name in overall dataframe, remove extraneous column
dat_field_maps <- left_join(dat_field_maps, species_map) %>%
  select(-fish_species, -species) %>%
  rename(species = common_name)

```

```{r}
# combine datasets from ESRI and Google Sheets

## ------------------------------------------------------------------
## 1. Identify columns common to both data frames
## ------------------------------------------------------------------

common_cols <- intersect(names(dat_field_maps), names(fish_dat))

## Optional: inspect type mismatches
type_compare <- tibble(
  col       = common_cols,
  fieldmap  = map_chr(common_cols, ~ class(dat_field_maps[[.x]])[1]),
  fishdat   = map_chr(common_cols, ~ class(fish_dat[[.x]])[1])
)
print(type_compare)

## ------------------------------------------------------------------
## 2. Align column types across common fields
##
##  - site_arrive_date  : POSIXct vs Date → convert both to Date
##  - site_depart_date  : POSIXct vs Date → convert both to Date
##  - site_arrive_time  : hms vs hms → enforce as_hms() 
##  - site_depart_time  : hms vs hms → enforce as_hms() 
##
## ------------------------------------------------------------------

dat_field_common <- dat_field_maps %>%
  select(all_of(common_cols)) %>%
  mutate(
    across(c(site_arrive_date, site_depart_date), as.Date),
    across(c(site_arrive_time, site_depart_time), as_hms)
  )

fish_dat_common <- fish_dat %>%
  select(all_of(common_cols)) %>%
  mutate(
    across(c(site_arrive_date, site_depart_date), as.Date),
    across(c(site_arrive_time, site_depart_time), as_hms)
  )

## ------------------------------------------------------------------
## 3. Bind rows into a single clean dataset
## ------------------------------------------------------------------

fish_all <- bind_rows(dat_field_common, fish_dat_common)


```

```{r echo = F}

# summary statistics

### how many unique sampling events (unique date/site) did we have?
n_events <- fish_all %>%
  group_by(latitude,longitude,site_arrive_date,site_arrive_time) %>%
  tally() %>%
  nrow() %>%
  as.character()

### how many unique event days did we have?
n_days <- fish_all %>%
  distinct() %>%
  select(site_arrive_date) %>%
  distinct() %>%
  nrow() %>%
  as.character()


### number of sites

#### total value only
n_sites_total <- fish_all %>%
  group_by(latitude, longitude) %>%
  tally() %>%
  nrow() %>%
  as.character()

#### table of number of site visits
n_sites_coords <- fish_all %>%
  group_by(site,latitude,longitude) %>%
  tally() %>%
  rename(site_visits = n)

### total fish
fish_ct <- fish_all %>%
  summarise(n = sum(count, na.rm = T)) %>%
  as.character()

### total unique species
spp_ct <- fish_all %>%
  filter(!is.na(species)) %>%
  group_by(species) %>%
  summarise(n = sum(count)) %>%
  nrow() %>%
  as.character()

### count by species table
spp_ct_n <- fish_all %>%
  group_by(species) %>%
  summarise(n = sum(count))

### count by species at each site
site_spp_ct <- fish_all %>%
  group_by(species,site,latitude, longitude) %>%
  summarise(n = sum(count)) %>%
  pivot_wider(names_from = "species", values_from = "n") %>%
  filter(!is.na(site)) %>%
  select(-"NA")

### total fish at each site table
total_by_site <- fish_all %>%
  group_by(site, latitude, longitude) %>%
  summarise(total_fish = sum(count)) %>%
  filter(!is.na(latitude))

#### join site totals to species totals by site
z <- left_join(site_spp_ct,total_by_site)

#### remove NAs
site_spp_ct[is.na(site_spp_ct)] <- 0

```

*Note: All fishing effort and capture results are current as of `r Sys.Date()`.*

## Fish capture

During fieldwork in summers 2021 - 2025:

-   Over course of `r n_days` fieldwork days 2021 - 2025 (including the training events), we conducted a total of `r n_events` sampling events at `r n_sites_total` unique sites. See the interactive project map in the Methods section ("Site selection") for a current map of where nominations have occurred.

-   Table @tbl-sites summarises total sampling events by individual site. We typically sampled a site only one time each.

-   We have captured `r fish_ct` fish comprised of `r spp_ct` unique species. Table @tbl-ct-spp summarizes current fish capture count by species.

-   Table @tbl-site-spp-ct summarizes total fish capture for each species by site.

```{r echo = F}
#| label: tbl-sites
#| tbl-cap: "Site visit count 2021 - 2025"

n_sites_coords %>%
  kbl(caption = "Total site visits") %>%
  kable_paper(full_width = F, html_font = "Cambria") %>%
  scroll_box(height = "500px", width = "350px")

# export csv
write.csv(n_sites_coords,"output/site_visits_coords.csv", row.names = F)

```

<br>

```{r , echo = F}
#| label: tbl-ct-spp
#| tbl-cap: "Total fish capture count by species 2021 - 2025"

spp_ct_n %>%
  kbl(caption = "Total fish capture count by species") %>%
  kable_paper(full_width = F, html_font = "Cambria")  %>%
  scroll_box(height = "600px", width = "350px")
#, 
 #             bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

<br>

```{r echo = F}
#| label: tbl-site-spp-ct
#| tbl-cap: "Species count by site 2021 -2025"
site_spp_ct %>%
  kbl(caption = "Total fish capture count by species at each site.") %>%
  kable_paper(full_width = F, html_font = "Cambria",

              bootstrap_options = c("condensed")) %>%
  kable_styling(latex_options = c("scale_down","striped")) %>%
  scroll_box(width = "100%", height = "500px")

write.csv(site_spp_ct,"output/site_spp_ct.csv", row.names = F)

```

<br>

## AWC Nominations

Fish capture data was evaluated against the 2025 Anadromous Waters Catalog to identify new stream segment nominations. Complete submission materials for 2021 - 2023 may be accessed in the project [Google Drive folder (link)](https://drive.google.com/drive/folders/1UmQGruxbmRO-ICCd0xbGi5rPp1ZTFCX2?usp=drive_link), sent to the ADF&G Habitat Division in Anchorage in the fall of each year. In 2024 we submitted all nominations through the Fish Map App smartphone application from the Alaska Conservation Foundation

::: {.callout-note appearance="simple"}
## Total Anadromous Waters Nominations

As of October 2025, a total length of approximately **24.5 miles** of stream segments and **173 lake acres** were included in our 25 nominations.
:::

Tables @tbl-awc-noms and @tbl-awc-noms-lakes below breaks down each stream segment nomination by length and lake by area.

```{r echo = F}
#| label: tbl-awc-noms
#| tbl-cap: "Lengths of stream segments included in anadromous waters nominations."

### nomination records
noms_tbl <- read_excel("input/2021_2025_stream_lengths.xlsx") %>%
  clean_names() %>%
  select(nomination,nomination_name,shape_length) %>%
  # convert from m to km
  mutate(shape_length = shape_length/1000) %>%
  rename(stream_length_km = shape_length) %>%
  filter(!is.na(nomination_name)) %>%
  group_by(nomination_name, nomination) %>%
  summarise(total_stream_length_km = sum(stream_length_km)) %>%
  arrange(nomination)

# stream table
noms_tbl %>%
  kbl(caption = "AWC Stream Nominations 2021 - 2025", digits = 2) %>%
  kable_paper(full_width = F, html_font = "Cambria")

```

<br>

```{r echo = F}
#| label: tbl-awc-noms-lakes
#| tbl-cap: "Lake areas included in anadromous waters nominations."

### nomination records
noms_tbl_lakes <- read_excel("input/2021_2025_lake_areas.xlsx") %>%
  clean_names() 

# lakes table
noms_tbl_lakes %>%
  kbl(caption = "AWC Lake Nominations 2021 - 2025", digits = 2) %>%
  kable_paper(full_width = F, html_font = "Cambria")

```

<br>

```{r echo = F}
#| label: fig-awc-noms-map
#| fig-cap: "Nominated stream segments highlighted in orange, green, turquoise, and yellow. Prexisting documented anadromous waters prior to this project colored in light blue."
knitr::include_graphics('images/2021_2025_awc_noms_graphic.jpg')

```

<br>

For general background on nominations, see the [slides linked here](https://docs.google.com/presentation/d/1uQX9_4T-vJDzp_gzBJFyqtggOg1Fpsng?rtpof=true&usp=drive_fs), presented at Kenai Watershed Forum's Fireside Chat series held at Kenai River Brewing on November 1, 2023.

Or, see the presentation below on Kenai Watershed Forum's YouTube channel

{{< video https://www.youtube.com/watch?v=u62Md_aYzPk >}}

## Volunteer participation

Volunteer recruitment efforts resulted in a steadily increasing level of participation from the general public. A total of 665 volunteer hours were documented throughout the project, with higher outlays in 2021 and 2025 to initiate training.

<br>

```{r echo = F}
# volunteer hours prep
vol_hrs <- read_sheet(url, sheet = "hours_records") %>%
  clean_names() %>%
  select(year,training_vs_fieldwork,total_time_hours) %>%
  group_by(year,training_vs_fieldwork) %>%
  summarise(hrs = sum(total_time_hours)) %>%
  filter(!is.na(hrs))

# plot
vol_hrs %>%
  ggplot(aes(as.character(year),hrs,fill = training_vs_fieldwork)) +
  geom_bar(stat = "identity", position = "dodge") +
  xlab("") +
  ylab("Volunteer Hours") +
  theme(legend.title=element_blank()) +
  ggtitle("Central Kenai Peninsula Salmon Habitat Mapping\nVolunteer Hours 2021-2025")

```

The level of volunteer participation, along with experience gained, mostly tracked the quantity of nominations submitted each year, with a steadily rising number of nominations from 2021 to 2023. 2024 saw very minimal funding resources directed towards fieldwork, thus the number of volunteer hours declined. Despite this reduced funding in 2024, seven nominations were submitted. The result speaks to how sustained financial support, even if fluctuating in amount, is important to keep projects such as this in progress.

In 2025, several training events were held in collaboration with Cook Inletkeeper as part of our shared [`Backyard Salmonscapes`](https://www.peninsulaclarion.com/news/cook-inletkeeper-program-promotes-community-engagement/) program. Volunteers also contributed efforts to our technical mapping efforts in progress, in collaboration with consultants Terrainworks and Romey Riverscape Sciences. [Click here to read more](https://www.kenaiwatershed.org/news-media/fish-habitat-mapping-2025/) on our new freshwater fish habitat mapping efforts on Kenai Watershed Forum's website.

<br>

```{r echo = F}
# plot
noms_tbl %>%
  group_by(nomination) %>%
  tally() %>%
  ggplot(aes(nomination,n)) +
  geom_bar(stat = "identity") +
  xlab("") +
  ylab("Number of AWC Nominations Submitted") +
  ggtitle("Number of Anadromous Waters Nominations\nSubmitted to the Alaska Department of Fish and Game\n2021 - 2025")

```

## Aquatic Resource Permit

Fish capture data was reformatted each fall in to a csv file for submission to ADF&G in fulfillment of the required [Aquatic Resource Permit](http://www.adfg.alaska.gov/index.cfm?adfg=otherlicense.aquatic_reports)[^results-1]; available in the online in [this project's GitHub repo](https://github.com/Kenai-Watershed-Forum/tu_awc_expansion/tree/main/output)[^results-2].

[^results-1]: <http://www.adfg.alaska.gov/index.cfm?adfg=otherlicense.aquatic_reports>

[^results-2]: <https://github.com/Kenai-Watershed-Forum/tu_awc_expansion/tree/main/output>

```{r, echo = F}

# prep data format for ARP report: https://www.adfg.alaska.gov/sf/SARR/AWC/index.cfm?ADFG=nomSubmit.about

# Notes for 2025
# same as above, we need to integrate data sources from both ESRI Field Maps as well as KWF's gogle sheets database

# read in google sheets sample effort database
sample_effort <- read_sheet(url, sheet = "C_Sample_Effort") %>%
  filter(!is.na(gear_type)) %>%
  select(site,site_depart_date, gear_type) %>%
  distinct()


# format ESRI Field Maps effort database (location, departure date, gear type)
z <- dat_field_maps |>
  # some sites have electrofishing only, some sites minnow traps only, some sites have both
  
  select(site_depart_date)

# join google sheets and ESRI data into same dataframe


# join sample effort data
fish_dat <- left_join(fish_dat,sample_effort, by = c("site","site_depart_date"))

# prepare data into ARP format
arp <- fish_dat %>%
  
  # rectify ARP column named "additional count"; leave blank if count = 1, make n-1 if count > 1
  # presumed that count = 1 if additional count = 0
  mutate(`Additional count (1)` = ifelse(fish_dat$count <= 1, "0",fish_dat$count - 1)) %>%
  
  # remove extraneous columns
  select(-site_arrive_time, -site_depart_time,-photo_id, -count, -camera_id, -project_org,
         -site_arrive_date) %>%
  
  # rename existing columns
  rename(`Latitude (decimal degrees)` = latitude,
         `Longitude (decimal degrees)` = longitude,
         Date = site_depart_date,
         `Location ID (optional)` = site,
         Species = species,
         `Life stage` = lifestage,
         `Weight (g)` = wt_g,
         `Length (mm) (NO estimates or ranges)` = fl_mm,
         `Length method` = length_method,
         `Disposition (1)` = disposition,
         Comments = notes,
         `Fish collection method` = gear_type) %>%
  
  # remove extraneous columns
  select(-observer_name) %>%
  
  # create missing columns
  mutate(Datum = "",
         `Coordinate determination method` = "",
         `Name of water body` = fish_dat$site,
         `Observer name (the first and last name of the person handling fish)` = fish_dat$observer_name,
         `Age method (sample type)` = "",
         `ADF&G GCL` = "",
         `Additional count (2)` = "",
  `Disposition (2)` = "",
  `Anesthesia/ Sedative Used (Leave blank if none used)` = "",
  Sex = "",
  Age = ""
         ) %>%
  

  
  # order columns to match ARP
  select(
  `Location ID (optional)`,
  `Latitude (decimal degrees)`,
  `Longitude (decimal degrees)`,
  Datum,
  `Coordinate determination method`,
  `Name of water body`,
  Date,
  `Observer name (the first and last name of the person handling fish)`,
  `Fish collection method`,
  `Species`,
  `Life stage`,
  `Length (mm) (NO estimates or ranges)`,
  `Length method`,
  `Weight (g)`,
  Sex,
  Age,
  `Age method (sample type)`,
  `ADF&G GCL`,
  `Additional count (1)`,
  `Disposition (1)`,
  `Additional count (2)`,
  `Disposition (2)`,
  `Anesthesia/ Sedative Used (Leave blank if none used)`,
  Comments						
  )

# export csv to repo
write_csv(arp, "output/aquatic_resource_permit_all.csv")

```
